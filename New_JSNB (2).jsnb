{
  "metadata": {
    "name": "New JSNB",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "// Dynamic script loading function\nasync function loadScript(src) {\n    return new Promise((resolve, reject) => {\n        const script = document.createElement('script');\n        script.src = src;\n        script.onload = () => resolve();\n        script.onerror = (err) => reject(err);\n        document.head.appendChild(script);\n    });\n}\n\n// Wait for the scripts to be loaded\nasync function initialize() {\n    await loadScript(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.13.0/dist/tf.min.js\");\n    await loadScript(\"https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet\");\n    await setupWebcam();\n    await loadModel();\n}\n\nlet videoElement = document.getElementById('myVideo');\nlet cameraStream;\nconst samples = {};\nconst alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ';  // Array of all labels (A to Z)\nalphabet.split('').forEach(letter => samples[letter] = []); \nlet mobilenetModel, classifier;\n\nasync function setupWebcam() {\n    if (!cameraStream) {\n        cameraStream = await navigator.mediaDevices.getUserMedia({ video: true });\n        videoElement.srcObject = cameraStream;\n        console.log(\"Webcam initialized\");\n    }\n}\n\nasync function loadModel() {\n    if (!mobilenetModel) {\n        mobilenetModel = await mobilenet.load();\n        console.log(\"MobileNet model loaded\");\n    }\n}\n\nasync function captureSample(label) {\n    if (!mobilenetModel) {\n        await initialize(); // Initialize if not already done\n    }\n\n    const img = tf.browser.fromPixels(videoElement);\n    const resized = tf.image.resizeBilinear(img, [224, 224]);\n    const features = mobilenetModel.infer(resized, 'conv_preds');\n    samples[label].push(features);\n\n    img.dispose();\n    resized.dispose();\n\n    // Corrected string interpolation\n    document.getElementById('output').innerText =` Captured ${samples[label].length} samples for '${label}'`;\n}\n\nasync function trainModel() {\n    if (alphabet.split('').every(letter => samples[letter].length > 0)){\n        const trainingData = [];\n        const trainingLabels = [];\n\n        // Prepare training data and labels\n        for (const label in samples) {\n            const labelSamples = samples[label];\n            for (let sample of labelSamples) {\n                trainingData.push(sample);\n                trainingLabels.push(label);\n            }\n        }\n\n        const xs = tf.concat(trainingData);\n        const ys = tf.tensor1d(trainingLabels.map(label => label === 'A' ? 0 : (label === 'B' ? 1 : 2)), 'int32').toFloat();\n\n        // If the classifier already exists, dispose of it to avoid conflicts\n        if (classifier) {\n            classifier.dispose(); // Dispose of previous model and its weights\n            classifier = null; // Set the reference to null to prevent reusing it\n        }\n\n        // Create a new model from scratch\n        classifier = tf.sequential();\n        classifier.add(tf.layers.dense({ inputShape: [xs.shape[1]], units: 64, activation: 'relu' }));\n        classifier.add(tf.layers.dense({ units: 3, activation: 'softmax' }));\n\n        classifier.compile({ loss: 'sparseCategoricalCrossentropy', optimizer: 'adam', metrics: ['accuracy'] });\n\n        // Train the model with the new data\n        await classifier.fit(xs, ys, { epochs: 10 });\n\n        // Dispose of training data tensors to free memory\n        xs.dispose();\n        ys.dispose();\n\n        alert('Model trained!');\n    } else {\n        alert('Please capture samples for A, B, and C before training.');\n    }\n}\n\nasync function startPrediction() {\n    if (!classifier) {\n        alert('Please train the model first.');\n        return;\n    }\n\n    let isPredicting = true;\n    const video = document.createElement('video');\n    video.width = 640;\n    video.height = 480;\n    video.autoplay = true;\n    document.body.appendChild(video);\n\n    const cameraStream = await navigator.mediaDevices.getUserMedia({ video: true });\n    video.srcObject = cameraStream;\n\n    // Wait for the video to be ready\n    await new Promise(resolve => {\n        video.onloadeddata = () => resolve(); // Wait for the 'loadeddata' event\n    });\n\n    // Now the video is ready, start the prediction loop\n    while (isPredicting) {\n        const img = tf.browser.fromPixels(video);\n        const resized = tf.image.resizeBilinear(img, [224, 224]);\n        const features = mobilenetModel.infer(resized, 'conv_preds');\n\n        // Reshape the features to be 2D (batch size of 1 and flattened features)\n        const reshapedFeatures = features.reshape([1, -1]);\n\n        // Make the prediction\n        const prediction = classifier.predict(reshapedFeatures);\n\t  const predictedIndex = (await prediction.argMax(1).data())[0];\n        const predictedLabel = alphabet[predictedIndex]; \n        //const predictedLabel = (await prediction.argMax(1).data())[0] === 0 ? 'A' : (prediction.argMax(1).data()[0] === 1 ? 'B' : 'C');\n\n        // Log the prediction to the console\n        console.log(\"Predicted Label:\", predictedLabel);\n\n        // Check if the prediction element exists before updating\n        const predictionElement = document.getElementById(\"prediction\");\n        if (predictionElement) {\n            predictionElement.innerText = predictedLabel;\n        } else {\n            console.warn('Element with id \"prediction\" not found');\n        }\n\n        img.dispose();\n        resized.dispose();\n        features.dispose();\n        reshapedFeatures.dispose();\n        prediction.dispose();\n        await tf.nextFrame();\n    }\n}\n\n// Initialize everything after page load\nwindow.onload = initialize;",
      "status": "[3]<br><span style=\"font-size:8px\">1ms<span></span></span>",
      "output": "async function initialize() {\n    await loadScript(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.13.0/dist/tf.min.js\");\n    await loadScript(\"https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet\");\n    await setupWebcam();\n    await loadModel();\n} <br>",
      "type": "code"
    },
    {
      "code": "//>html\n//>html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Sign Language Detector</title>\n    <style>\n        body { text-align: center; font-family: Arial, sans-serif; }\n        #myVideo { border: 1px solid black; margin-top: 10px; }\n        .controls { margin-top: 20px; }\n        button { padding: 10px 20px; margin: 5px; }\n        #output { font-size: 20px; margin-top: 10px; color: green; }\n    </style>\n</head>\n<body>\n    <h1>Sign Language Detector</h1>\n    <video id=\"myVideo\" width=\"640\" height=\"480\" autoplay playsinline></video>\n    <div class=\"controls\">\n        <button onclick=\"captureSample('A')\">Capture 'A'</button>\n<button onclick=\"captureSample('B')\">Capture 'B'</button>\n<button onclick=\"captureSample('C')\">Capture 'C'</button>\n<button onclick=\"captureSample('D')\">Capture 'D'</button>\n<button onclick=\"captureSample('E')\">Capture 'E'</button>\n<button onclick=\"captureSample('F')\">Capture 'F'</button>\n<button onclick=\"captureSample('G')\">Capture 'G'</button>\n<button onclick=\"captureSample('H')\">Capture 'H'</button>\n<button onclick=\"captureSample('I')\">Capture 'I'</button>\n<button onclick=\"captureSample('J')\">Capture 'J'</button>\n<button onclick=\"captureSample('K')\">Capture 'K'</button>\n<button onclick=\"captureSample('L')\">Capture 'L'</button>\n<button onclick=\"captureSample('M')\">Capture 'M'</button>\n<button onclick=\"captureSample('N')\">Capture 'N'</button>\n<button onclick=\"captureSample('O')\">Capture 'O'</button>\n<button onclick=\"captureSample('P')\">Capture 'P'</button>\n<button onclick=\"captureSample('Q')\">Capture 'Q'</button>\n<button onclick=\"captureSample('R')\">Capture 'R'</button>\n<button onclick=\"captureSample('S')\">Capture 'S'</button>\n<button onclick=\"captureSample('T')\">Capture 'T'</button>\n<button onclick=\"captureSample('U')\">Capture 'U'</button>\n<button onclick=\"captureSample('V')\">Capture 'V'</button>\n<button onclick=\"captureSample('W')\">Capture 'W'</button>\n<button onclick=\"captureSample('X')\">Capture 'X'</button>\n<button onclick=\"captureSample('Y')\">Capture 'Y'</button>\n<button onclick=\"captureSample('Z')\">Capture 'Z'</button>\n\n        <button onclick=\"trainModel()\">Train Model</button>\n        <button onclick=\"startPrediction()\">Start Prediction</button>\n    </div>\n    <div id=\"output\">Prediction: <span id=\"prediction\"></span></div>\n</body>\n</html>",
      "status": "[4]<br><span style=\"font-size:8px\">1ms<span></span></span>",
      "output": "\n//&gt;html\n\n\n\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Sign Language Detector</title>\n    <style>\n        body { text-align: center; font-family: Arial, sans-serif; }\n        #myVideo { border: 1px solid black; margin-top: 10px; }\n        .controls { margin-top: 20px; }\n        button { padding: 10px 20px; margin: 5px; }\n        #output { font-size: 20px; margin-top: 10px; color: green; }\n    </style>\n\n\n    <h1>Sign Language Detector</h1>\n    <video id=\"myVideo\" width=\"640\" height=\"480\" autoplay=\"\" playsinline=\"\"></video>\n    <div class=\"controls\">\n        <button onclick=\"captureSample('A')\">Capture 'A'</button>\n<button onclick=\"captureSample('B')\">Capture 'B'</button>\n<button onclick=\"captureSample('C')\">Capture 'C'</button>\n<button onclick=\"captureSample('D')\">Capture 'D'</button>\n<button onclick=\"captureSample('E')\">Capture 'E'</button>\n<button onclick=\"captureSample('F')\">Capture 'F'</button>\n<button onclick=\"captureSample('G')\">Capture 'G'</button>\n<button onclick=\"captureSample('H')\">Capture 'H'</button>\n<button onclick=\"captureSample('I')\">Capture 'I'</button>\n<button onclick=\"captureSample('J')\">Capture 'J'</button>\n<button onclick=\"captureSample('K')\">Capture 'K'</button>\n<button onclick=\"captureSample('L')\">Capture 'L'</button>\n<button onclick=\"captureSample('M')\">Capture 'M'</button>\n<button onclick=\"captureSample('N')\">Capture 'N'</button>\n<button onclick=\"captureSample('O')\">Capture 'O'</button>\n<button onclick=\"captureSample('P')\">Capture 'P'</button>\n<button onclick=\"captureSample('Q')\">Capture 'Q'</button>\n<button onclick=\"captureSample('R')\">Capture 'R'</button>\n<button onclick=\"captureSample('S')\">Capture 'S'</button>\n<button onclick=\"captureSample('T')\">Capture 'T'</button>\n<button onclick=\"captureSample('U')\">Capture 'U'</button>\n<button onclick=\"captureSample('V')\">Capture 'V'</button>\n<button onclick=\"captureSample('W')\">Capture 'W'</button>\n<button onclick=\"captureSample('X')\">Capture 'X'</button>\n<button onclick=\"captureSample('Y')\">Capture 'Y'</button>\n<button onclick=\"captureSample('Z')\">Capture 'Z'</button>\n\n        <button onclick=\"trainModel()\">Train Model</button>\n        <button onclick=\"startPrediction()\">Start Prediction</button>\n    </div>\n    <div id=\"output\"> Captured 5 samples for 'Z'</div>\n\n <br>",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/jsnb",
  "run_on_load": false
}